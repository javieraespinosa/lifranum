{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LIFRANUM-UAT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/javieraespinosa/lifranum/blob/main/LIFRANUM_UAT.ipynb",
      "authorship_tag": "ABX9TyOzaYerjiD1pheeGloZgVz5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javieraespinosa/lifranum/blob/main/LIFRANUM_UAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unYwCwjvg_Ct"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ-gJ-tsPg5z"
      },
      "source": [
        "Requirements:\n",
        "https://aut.docs.archivesunleashed.org/docs/dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3sdVnqmgGOZ"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F08YfGw-HBCw"
      },
      "source": [
        "SPARK_VERSION = \"spark-2.4.7-bin-hadoop2.7\"\n",
        "AUT_VERSION   = \"aut-0.80.0\"\n",
        "APPS_HOME     = os.getcwd() + \"/apps\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YADoCV7A2pWF"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKBNWTBU3fC6"
      },
      "source": [
        "!mkdir -p \"$APPS_HOME\"\n",
        "\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.7/\"$SPARK_VERSION\".tgz\n",
        "!wget -q https://github.com/archivesunleashed/aut/releases/download/\"$AUT_VERSION\"/\"$AUT_VERSION\".zip\n",
        "!wget -q https://github.com/archivesunleashed/aut/releases/download/\"$AUT_VERSION\"/\"$AUT_VERSION\"-fatjar.jar\n",
        "!tar -xf \"$SPARK_VERSION\".tgz\n",
        "!mv spark-* aut-* \"$APPS_HOME\"\n",
        "\n",
        "!wget -q https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -qq ngrok-stable-linux-amd64.zip\n",
        "!mv ngrok* \"$APPS_HOME\"\n",
        "\n",
        "!rm -rf sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge5UOwQJIDjs"
      },
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "SPARK_DRIVER_MEMORY   = \"8g\"\n",
        "\n",
        "os.environ[\"JAVA_HOME\"]  = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"{}/{}\".format(APPS_HOME, SPARK_VERSION)   \n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--driver-memory {0} --jars {2}/{1}-fatjar.jar --py-files {2}/{1}.zip pyspark-shell'.format(SPARK_DRIVER_MEMORY, AUT_VERSION, APPS_HOME)\n",
        "\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb-ED0zhZyGt"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "conf = pyspark.SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "sc = pyspark.SparkContext.getOrCreate(conf)\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0Y_CSDAWDaU"
      },
      "source": [
        "sc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WopTC0nitD2q"
      },
      "source": [
        "get_ipython().system_raw('{}/ngrok http 4050 &'.format(APPS_HOME))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_v1bc4Xtlr6"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5zschIXET7B"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPK40cWIkais"
      },
      "source": [
        "!mkdir data\n",
        "!wget -q \"https://github.com/archivesunleashed/aut-resources/blob/master/Sample-Data/ARCHIVEIT-227-UOFTORONTO-CANPOLPINT-20060622205612-00009-crawling025.archive.org.arc.gz?raw=true\" -O data/ARCHIVEIT-227-UOFTORONTO-CANPOLPINT-20060622205612-00009-crawling025.archive.org.arc.gz\n",
        "!wget -q \"https://github.com/archivesunleashed/aut-resources/blob/master/Sample-Data/ARCHIVEIT-227-QUARTERLY-XUGECV-20091218231727-00039-crawling06.us.archive.org-8091.warc.gz?raw=true\" -O data/ARCHIVEIT-227-QUARTERLY-XUGECV-20091218231727-00039-crawling06.us.archive.org-8091.warc.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj54c5TrthLu"
      },
      "source": [
        "# Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QieEJ_d8U0Vq"
      },
      "source": [
        "WARCs_PATH=\"/content/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwKYiQNWYR4X"
      },
      "source": [
        "## Bug: Correcting URLS in Wget's WARCs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3jbwFILYThE"
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "url_correction = udf(lambda s: s[1:-1] if len(s) > 0 and s[0] == '<' and s[-1] == '>' else s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FH00iPCNUWX"
      },
      "source": [
        "## Extract All URLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qRhNrI-amJQ"
      },
      "source": [
        "from aut import *\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "WebArchive(sc, sqlContext, WARCs_PATH) \\\n",
        "  .webpages() \\\n",
        "  .withColumn(\"url\", url_correction(\"url\")) \\\n",
        "  .select(\"url\") \\\n",
        "  .show(2, False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPVBtw2eDG4K"
      },
      "source": [
        "## Extract Top-Level Domains"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drkuA0SeN7fb"
      },
      "source": [
        "from aut import *\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "WebArchive(sc, sqlContext, WARCs_PATH) \\\n",
        "  .webpages() \\\n",
        "  .withColumn(\"url\", url_correction(\"url\")) \\\n",
        "  .select(extract_domain(\"url\").alias(\"domain\")) \\\n",
        "  .groupBy(\"domain\") \\\n",
        "  .count() \\\n",
        "  .sort(desc(\"count\")) \\\n",
        "  .show(10, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD2AVtQZwu_5"
      },
      "source": [
        "## Extract Simple Site Link Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R3VZCKVwucp"
      },
      "source": [
        "from aut import *\n",
        "from pyspark.sql.functions import col, explode\n",
        "\n",
        "content = \"%radio%\"\n",
        "\n",
        "WebArchive(sc, sqlContext, WARCs_PATH) \\\n",
        "  .webpages() \\\n",
        "  .withColumn(\"url\", url_correction(\"url\")) \\\n",
        "  .filter(col(\"content\").like(content)) \\\n",
        "  .select(explode(extract_links(\"url\", \"content\")).alias(\"links\")) \\\n",
        "  .select(remove_prefix_www(extract_domain(col(\"links._1\"))).alias(\"src\"), remove_prefix_www(extract_domain(col(\"links._2\"))).alias(\"dest\")) \\\n",
        "  .groupBy(\"src\", \"dest\") \\\n",
        "  .count() \\\n",
        "  .filter(col(\"count\") > 5) \\\n",
        "  .write.csv(\"links-all-apple-df/\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLpaNDH34RLs"
      },
      "source": [
        "## Finding Hyperlinks within Collection on Pages with Certain Keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T0Q1Msi4Q5Z"
      },
      "source": [
        "from aut import *\n",
        "from pyspark.sql.functions import col, explode_outer\n",
        "\n",
        "webpages = WebArchive(sc, sqlContext, WARCs_PATH) \\\n",
        "  .webpages() \\\n",
        "  .select(remove_prefix_www(extract_domain(\"url\")).alias(\"domain\"), \"url\", \"crawl_date\", explode_outer(extract_links(\"url\", \"content\")).alias(\"link\")) \\\n",
        "  .filter(col(\"content\").like(\"%food%\")) \\\n",
        "  .select(\"url\", \"domain\", \"crawl_date\", col(\"link._1\").alias(\"destination_page\")) \\\n",
        "  .show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRP6VYXH4aiX"
      },
      "source": [
        "## Export to Gephi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVwWXxrCapV6"
      },
      "source": [
        "from pyspark.sql.functions import col, desc\n",
        "\n",
        "graph = WebArchive(sc, sqlContext, WARCs_PATH) \\\n",
        "          .webgraph() \\\n",
        "          .withColumn(\"src\", url_correction(\"src\")) \\\n",
        "          .groupBy(\"crawl_date\", \"src\", \"dest\") \\\n",
        "          .count() \\\n",
        "          .filter((col(\"dest\").isNotNull()) & (col(\"dest\") !=\"\")) \\\n",
        "          .filter((col(\"src\").isNotNull()) & (col(\"src\") !=\"\")) \\\n",
        "          .filter(col(\"count\") > 5) \\\n",
        "          .orderBy(desc(\"count\")) \\\n",
        "          .collect()\n",
        "\n",
        "WriteGEXF(graph, \"links-for-gephi.gexf\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx3MmDEAiF98"
      },
      "source": [
        "# Resources\n",
        "\n",
        "* [A Must-Read Guide on How to Work with PySpark on Google Colab for Data Scientists!](https://www.analyticsvidhya.com/blog/2020/11/a-must-read-guide-on-how-to-work-with-pyspark-on-google-colab-for-data-scientists/)\n",
        "* [Archives Unleashed Toolkit](https://aut.docs.archivesunleashed.org/docs/dependencies)\n"
      ]
    }
  ]
}